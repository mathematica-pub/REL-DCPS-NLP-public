{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52121ec-7cb8-4f7b-a7de-1216f3f28600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd  \n",
    "print(os.getcwd())\n",
    "## Now read in the generate text function from the primary script\n",
    "from primary.generate_text import generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ad297-ddd1-4ba9-b503-385d70f8076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Prepare models\n",
    "model = \"./model/Meta-Llama-3-8B-Instruct-Q3_K_S.gguf\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454377e-ce2b-4331-b4ea-0e0b2d144980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Prepare School data for analysis\n",
    "# - Load the data from the Excel file\n",
    "data_directory = \"./data/\"\n",
    "# data_directory = \"C:/Users/pkress/projects/REL-DCPS-workshop/REL-DCPS-NLP-public/data/\"\n",
    "input_path = data_directory + \"Intervention Sample_lbNotes.csv\"\n",
    "goal_data = pd.read_csv(input_path)\n",
    "goal_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ec0df-520d-4a49-ae09-20319c1ef5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Preliminary cleaning\n",
    "keep_cols = [\"intervention_id\", \"subject_area\", \"grade_level\", \"school_id\"\n",
    "             , \"group_intervention_name\", \"strategies\", \"strategy_ids\", \"tier\"\n",
    "             , \"in_group\", \"plan_goal\"]\n",
    "cln_data = goal_data.dropna(\n",
    "    subset=[\"plan_goal\"]\n",
    "    ).loc[\n",
    "    :, keep_cols\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1541afb-9cfa-4d50-b39f-ca09b5ee4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Some initial exploration\n",
    "print(cln_data.groupby(['grade_level', \"subject_area\"]).intervention_id.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b29e8-efaf-430d-8752-30ff0e1cb933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(cln_data.groupby(['grade_level']).intervention_id.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079821a9-ae25-4712-ac62-58a9cc528225",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cln_data.loc[cln_data.grade_level==\"6\"].groupby(['subject_area']).intervention_id.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78903c9-0354-4bbc-8c08-08476745d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cln_data.loc[cln_data.grade_level==\"11\"].groupby(['subject_area']).intervention_id.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7907af-e098-40ed-836e-902bc8cdfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(cln_data.loc[cln_data.grade_level==\"C7\"].groupby(['subject_area']).intervention_id.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa8483-24f8-40d8-8e9e-c2a4ce4bbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Confirm intervention_id is unique\n",
    "cln_data.intervention_id.nunique() == cln_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6aac1-8c03-4147-8c88-e3d332bc417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get some goals!\n",
    "math_prompts = cln_data.loc[\n",
    "    (cln_data.grade_level==\"6\") & (cln_data.subject_area==\"Mathematics\")\n",
    "    ].sample(\n",
    "    3\n",
    "    ).loc[\n",
    "    :, [\"intervention_id\", \"plan_goal\"]\n",
    "    ] \n",
    "behave_prompts = cln_data.loc[\n",
    "    (cln_data.grade_level==\"6\") & (cln_data.subject_area==\"Behavior\")\n",
    "    ].sample(\n",
    "    3\n",
    "    ).loc[\n",
    "    :, [\"intervention_id\", \"plan_goal\"]\n",
    "    ]\n",
    "print(behave_prompts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e47b18-1882-4077-a288-b68517f854e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Simple \"Smart\" feedback\n",
    "system_prompt = \"\"\"\n",
    "You give feedback on the quality of the goals teachers set for their students. \n",
    "Treat all submitted text as a goal. \n",
    "Goals should be specific, measurable, achievable, and have a deadline.\n",
    "Give feedback on the extent to which goals are specific, measurable, achievable, or have a deadline.\n",
    "Include a numeric score for each category from 1 (needs improvement) to 5 (excellent). \n",
    "\"\"\"  \n",
    "math_simple = generate_text(math_prompts.plan_goal.tolist(),\n",
    "                 system_prompt = system_prompt, \n",
    "                 model_path = model,\n",
    "                 temperature = 0.0, \n",
    "                 n_ctx = 1024, max_tokens = 1024)  \n",
    "\n",
    "\n",
    "\n",
    "[print(\"________\\n\", math_simple['prompts'][i], \"\\n\", math_simple['responses'][i]) \\\n",
    "    for i in range(len(math_simple['responses']))]\n",
    "print(math_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91b101-4b87-4680-a9e2-f7a0256da361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Simple \"Smart\" feedback\n",
    "system_prompt = \"\"\"\n",
    "You are an expert on goal quality. \n",
    "Give feedback on the quality of the goals teachers set for their students. \n",
    "Treat all submitted text as a goal. \n",
    "First, give feedback on the specificity based on how specific the goal is. \n",
    "Second, give feedback on the achievability, based on whether you could expect a 6th grader to behave. \n",
    "Include a numeric score for each category from 1 (needs improvement) to 5 (excellent). \n",
    "\"\"\"  \n",
    "math_simple = generate_text(math_prompts.plan_goal.tolist(),\n",
    "                 system_prompt = system_prompt, \n",
    "                 model_path = model,\n",
    "                 temperature = 0.0, \n",
    "                 n_ctx = 1024, max_tokens = 1024)  \n",
    "\n",
    "\n",
    "\n",
    "[print(\"________\\n\", math_simple['prompts'][i], \"\\n\", math_simple['responses'][i]) \\\n",
    "    for i in range(len(math_simple['responses']))]\n",
    "print(math_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff89e3f-d74c-44f6-93b8-59477295a503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
